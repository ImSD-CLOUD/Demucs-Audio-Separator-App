# ğŸµ Demucs Audio Separator

> **AI-Powered Cloud-Native Audio Source Separation Application**

A production-ready, serverless web application that leverages state-of-the-art deep learning models to separate vocals and instrumentals from audio tracks. Built with scalable AWS infrastructure and modern web technologies.

[![Live Demo](https://img.shields.io/badge/demo-live-success)](https://your-netlify-url.netlify.app)
[![AWS](https://img.shields.io/badge/AWS-Deployed-orange)](https://aws.amazon.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## ğŸ¯ Project Overview

This application demonstrates **end-to-end AI model deployment** on AWS cloud infrastructure, showcasing expertise in:
- **Machine Learning Operations (MLOps)** - Containerized AI model deployment
- **Cloud Architecture** - Serverless, event-driven design patterns
- **Infrastructure as Code** - AWS services orchestration
- **Production ML Systems** - Real-time inference with auto-scaling

### Key Highlights
- ğŸ¤– **Deep Learning Model**: Facebook Research's Demucs (Hybrid Transformer Demucs)
- â˜ï¸ **Cloud-Native**: 100% serverless AWS infrastructure
- ğŸ“ˆ **Auto-Scaling**: Scales to zero when idle, reduces costs by 90%
- ğŸ”’ **Secure**: API Gateway with CORS, rate limiting, and IAM-based authentication
- âš¡ **Asynchronous Processing**: Handles long-running ML inference jobs efficiently

---

## ğŸ—ï¸ Architecture

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER INTERFACE                              â”‚
â”‚                     (React SPA on Netlify)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ HTTPS
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS HTTP API GATEWAY                            â”‚
â”‚  â€¢ CORS Protection      â€¢ Rate Limiting (10 req/sec)                â”‚
â”‚  â€¢ Request Validation   â€¢ CloudWatch Logging                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ IAM Auth
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS LAMBDA FUNCTIONS                            â”‚
â”‚                        (Node.js 24.x)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Upload Lambda  â”‚Process Lambdaâ”‚ Status Lambdaâ”‚  Cleanup Lambda     â”‚
â”‚  (Presigned URL)â”‚ (Start Job)  â”‚(Poll Results)â”‚ (Delete Files)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚              â”‚
         â”‚               â”‚              â”‚
         â–¼               â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AMAZON S3                                    â”‚
â”‚  â€¢ Input Storage        â€¢ Output Storage                            â”‚
â”‚  â€¢ Session Management   â€¢ Presigned URLs (1hr expiry)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ S3 Event Trigger
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               AMAZON SAGEMAKER ASYNCHRONOUS INFERENCE                â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚          CUSTOM DOCKER CONTAINER (ECR)                 â”‚        â”‚
â”‚  â”‚  â€¢ Base: NVIDIA CUDA 11.8 + cuDNN 8                   â”‚        â”‚
â”‚  â”‚  â€¢ Framework: PyTorch with GPU support                â”‚        â”‚
â”‚  â”‚  â€¢ AI Model: Demucs (htdemucs) - Hybrid Transformer   â”‚        â”‚
â”‚  â”‚  â€¢ Server: Flask (serve.py) on port 8080              â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                      â”‚
â”‚  Instance: ml.g4dn.xlarge (NVIDIA T4 GPU)                          â”‚
â”‚  Auto-scaling: Scales to 0 when idle â†’ Cost Optimized              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
1. User uploads audio file (MP3/WAV/FLAC)
   â†“
2. Frontend requests presigned S3 URL from Upload Lambda
   â†“
3. Direct upload to S3 (bypasses API Gateway for large files)
   â†“
4. Process Lambda invokes SageMaker async endpoint
   â†“
5. SageMaker spins up containerized AI model
   â†“
6. Demucs model performs source separation (vocals + instrumentals)
   â†“
7. Output files uploaded to S3 with session-specific prefix
   â†“
8. Frontend polls Status Lambda every 5 seconds
   â†“
9. Status Lambda returns presigned download URLs
   â†“
10. User downloads separated tracks (vocals.wav, no_vocals.wav)
```

---

## ğŸ§  AI/ML Technology Stack

### Deep Learning Model
- **Model**: [Demucs v4 (Hybrid Transformer Demucs)](https://github.com/facebookresearch/demucs)
  - State-of-the-art music source separation
  - Hybrid architecture: Transformers + Convolutional layers
  - Two-stem separation: vocals and instrumental (no_vocals)
- **Framework**: PyTorch with CUDA acceleration
- **Inference Time**: 10-15 minutes per 3-minute song (GPU-accelerated)

### ML Infrastructure
- **Containerization**: Docker with NVIDIA CUDA runtime
- **Model Serving**: Custom Flask inference server (`serve.py`)
- **Deployment**: AWS SageMaker Asynchronous Inference
- **Compute**: GPU instance (ml.g4dn.xlarge with NVIDIA T4)
- **Scaling**: Auto-scales to zero instances when idle

### Key ML Operations Features
1. **Model Containerization**: Custom Docker image with all dependencies
2. **CI/CD Pipeline**: AWS CodeBuild â†’ ECR â†’ SageMaker
3. **Asynchronous Inference**: Handles long-running ML jobs without blocking
4. **GPU Optimization**: CUDA 11.8 with cuDNN for accelerated inference
5. **Cost Efficiency**: Pay-per-use model with auto-scaling

---

## ğŸ› ï¸ Technology Stack

### Frontend
- **Framework**: React 18
- **Styling**: Inline styles with modern gradients
- **Hosting**: Netlify (CDN-backed, auto-deploy)
- **Features**: Real-time status polling, progress indicators

### Backend (AWS Services)
- **API Layer**: HTTP API Gateway
  - RESTful endpoints
  - CORS configuration
  - Throttling: 20 req/sec, 30 burst
  
- **Compute**: AWS Lambda (Node.js 24.x)
  - Upload Handler
  - Processing Orchestrator
  - Status Checker
  - Cleanup Service

- **AI/ML**: Amazon SageMaker
  - Asynchronous Inference Endpoint
  - Custom Docker Container (ECR)
  - GPU Instance: ml.g4dn.xlarge

- **Storage**: Amazon S3
  - Input file storage
  - Session-based output organization
  - Presigned URLs for secure downloads

- **Container Registry**: Amazon ECR
  - Docker image versioning
  - Automated builds via CodeBuild

- **Monitoring**: Amazon CloudWatch
  - Lambda execution logs
  - API Gateway metrics
  - SageMaker endpoint monitoring

---

## ğŸ“¦ Project Structure

```
Demucs-Audio-Separator/
â”œâ”€â”€ demucs-sagemaker-backend/
â”‚   â”œâ”€â”€ buildspec.yml           # AWS CodeBuild configuration
â”‚   â”œâ”€â”€ Dockerfile              # SageMaker container definition
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ serve.py                # Flask inference server
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ node_modules/           # Dependencies (generated)
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html          # HTML template
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js              # React application
â”‚   â”‚   â”œâ”€â”€ index.css           # Global styles
â”‚   â”‚   â””â”€â”€ index.js            # React entry point
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ package.json            # Frontend dependencies
â”‚   â””â”€â”€ netlify.toml            # Netlify deployment config
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

**Note**: Lambda functions are deployed separately and not included in this repository. They are managed directly in AWS Lambda console.

---

## ğŸš€ Deployment Guide

### Prerequisites
- AWS Account with appropriate IAM permissions
- AWS CLI configured
- Docker installed (for local testing)
- Node.js 24.x
- Netlify account

### Step 1: Build and Deploy SageMaker Container

```bash
# Navigate to SageMaker directory
cd backend/sagemaker

# Build Docker image
docker build -t demucs-inference .

# Tag for ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com
docker tag demucs-inference:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/demucs-inference:latest

# Push to ECR
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/demucs-inference:latest
```

### Step 2: Create SageMaker Async Endpoint

```bash
# Create model from ECR image
aws sagemaker create-model \
  --model-name demucs-model \
  --primary-container Image=<account-id>.dkr.ecr.us-east-1.amazonaws.com/demucs-inference:latest \
  --execution-role-arn <sagemaker-role-arn>

# Create endpoint configuration
aws sagemaker create-endpoint-config \
  --endpoint-config-name demucs-async-config \
  --production-variants VariantName=variant1,ModelName=demucs-model,InstanceType=ml.g4dn.xlarge,InitialInstanceCount=1 \
  --async-inference-config OutputConfig={S3OutputPath=s3://your-bucket/sagemaker-output/}

# Create async endpoint
aws sagemaker create-endpoint \
  --endpoint-name demucs-async-endpoint \
  --endpoint-config-name demucs-async-config
```

### Step 3: Deploy Lambda Functions

```bash
# Deploy each Lambda function
cd backend/lambda/upload
zip -r upload.zip .
aws lambda create-function \
  --function-name demucs-upload \
  --runtime nodejs24.x \
  --handler index.handler \
  --zip-file fileb://upload.zip \
  --role <lambda-role-arn>

# Repeat for process, status, and cleanup Lambdas
```

### Step 4: Configure HTTP API Gateway

1. Create HTTP API in AWS Console
2. Add routes: `/upload`, `/process`, `/status`, `/cleanup`
3. Integrate each route with corresponding Lambda
4. Configure CORS for your Netlify domain
5. Enable throttling (20 req/sec)
6. Deploy to production stage

### Step 5: Deploy Frontend

```bash
cd frontend
npm install
npm run build

# Deploy to Netlify
netlify deploy --prod
```

### Step 6: Update Environment Variables

Update `App.js` with your API Gateway URL:
```javascript
const API_BASE_URL = 'https://your-api-id.execute-api.us-east-1.amazonaws.com';
```

---

## ğŸ’° Cost Analysis

**Monthly cost for 10 uploads (~10 songs)**:

| Service | Usage | Cost |
|---------|-------|------|
| SageMaker (ml.g4dn.xlarge) | ~2.5 hours/month | $13.15 |
| Lambda Invocations | ~100 requests | $0.00 |
| API Gateway (HTTP) | ~100 requests | $0.00 |
| S3 Storage | ~500 MB | $0.01 |
| ECR Storage | ~5 GB | $0.50 |
| **Total** | | **~$13.66/month** |

**Cost Optimization**:
- Async inference scales to 0 â†’ No idle costs
- Using HTTP API instead of REST API â†’ 70% cheaper
- Direct S3 uploads â†’ Reduces Lambda data transfer costs

---

## ğŸ”’ Security Features

1. **API Gateway Protection**
   - CORS restricted to frontend domain
   - Rate limiting (prevents DDoS)
   - Request/response validation

2. **IAM-Based Authentication**
   - Lambda functions only accessible via API Gateway
   - SageMaker role with least-privilege access
   - S3 bucket policies for secure storage

3. **Presigned URLs**
   - Time-limited access (1 hour expiry)
   - No public S3 bucket access
   - Secure file upload/download

4. **No Direct Lambda URLs**
   - Function URLs disabled
   - All traffic routes through API Gateway

---

## ğŸ“Š Performance Metrics

- **Cold Start**: ~3-5 seconds (Lambda)
- **SageMaker Spin-up**: ~2-3 minutes (first request)
- **Processing Time**: 10-15 minutes per 3-minute song
- **File Size Limit**: Recommended < 50MB
- **Concurrent Processing**: 1 instance (can scale horizontally)

---

## ğŸ“ Learning Outcomes

This project demonstrates:

### Cloud Architecture
âœ… Designing serverless, event-driven systems  
âœ… Implementing cost-efficient auto-scaling solutions  
âœ… Securing APIs with proper authentication and authorization  
âœ… Managing infrastructure on AWS (IaaS, PaaS, SaaS)

### Machine Learning Engineering
âœ… Containerizing deep learning models with Docker  
âœ… Deploying ML models to production (MLOps)  
âœ… Optimizing GPU-based inference workloads  
âœ… Implementing asynchronous ML inference patterns  
âœ… Managing model artifacts and versioning

### Software Engineering
âœ… Building full-stack applications (React + Node.js)  
âœ… API design and implementation (RESTful)  
âœ… Error handling and logging strategies  
âœ… CI/CD pipelines for containerized applications

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: SageMaker endpoint takes too long to respond
- **Solution**: Check CloudWatch logs for model loading issues
- **Tip**: First request after idle period takes 2-3 minutes for instance spin-up

**Issue**: CORS errors in browser
- **Solution**: Verify API Gateway CORS configuration matches Netlify domain
- **Tip**: Clear browser cache after updating CORS settings

**Issue**: Lambda timeout errors
- **Solution**: Increase Lambda timeout to 30 seconds in configuration
- **Tip**: Ensure Lambda has VPC access if SageMaker is in VPC

**Issue**: Out of memory errors in container
- **Solution**: Demucs requires ~8GB RAM, ensure ml.g4dn.xlarge is used
- **Tip**: Monitor CloudWatch Container Insights for memory usage

---

## ğŸš§ Future Enhancements

- [ ] Support for 4-stem separation (vocals, drums, bass, other)
- [ ] Real-time progress updates via WebSocket
- [ ] Batch processing for multiple files
- [ ] User authentication with AWS Cognito
- [ ] Custom model fine-tuning interface
- [ ] Download history with DynamoDB
- [ ] Email notifications on completion (SNS)
- [ ] Support for video file audio extraction

---

## ğŸ“š Resources

- [Demucs GitHub Repository](https://github.com/facebookresearch/demucs)
- [AWS SageMaker Async Inference Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html)
- [HTTP API Gateway Guide](https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api.html)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Swarup Das**
- LinkedIn: [Swarup Das](https://www.linkedin.com/in/swarup-das-17bb03202)
- Portfolio: [swarupdas-portfolio](https://swarupdas-portfolio.netlify.app)
- Email: sarupsarup66@gmail.com

---

## ğŸ™ Acknowledgments

- Facebook Research for the Demucs model
- AWS for comprehensive cloud infrastructure
- Open-source community for tools and libraries

---


**â­ If you found this project helpful, please consider giving it a star!**

Made with â¤ï¸ and â˜ï¸
